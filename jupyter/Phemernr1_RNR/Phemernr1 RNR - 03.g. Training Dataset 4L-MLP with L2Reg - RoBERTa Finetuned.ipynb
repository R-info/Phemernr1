{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# random.seed(33)\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr1-RNR\"\n",
    "unique_name = \"RoBERTa_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5802, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr1-RNR_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOMBSHELL: #Ferguson chief says the police off...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It appears that #Ferguson PD are trying to ass...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All weekend ppl will be talking about the \"rob...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why would the officer tell #MikeBrown to get o...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael Brown is the 17 yr old boy who was sho...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>training</td>\n",
       "      <td>0</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text     topic    label  \\\n",
       "0  BOMBSHELL: #Ferguson chief says the police off...  ferguson  rumours   \n",
       "1  It appears that #Ferguson PD are trying to ass...  ferguson  rumours   \n",
       "2  All weekend ppl will be talking about the \"rob...  ferguson  rumours   \n",
       "3  Why would the officer tell #MikeBrown to get o...  ferguson  rumours   \n",
       "4  Michael Brown is the 17 yr old boy who was sho...  ferguson  rumours   \n",
       "\n",
       "        tvt  cv_fold        tvt2  \n",
       "0      test        3    training  \n",
       "1  training        1    training  \n",
       "2      test        3    training  \n",
       "3      test        3    training  \n",
       "4  training        0  validation  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr1_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f76a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "maritime-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] == \"rumours\":\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3902, 768)\n",
      "(1325, 768)\n",
      "(575, 768)\n",
      "(3902,)\n",
      "(1325,)\n",
      "(575,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1\n",
    "    ):\n",
    "        super(NNModel, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, n_output)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "    \n",
    "\n",
    "class NNClassifier:\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = NNModel(n_input, n_output)\n",
    "\n",
    "        self.criterion = criterion()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)\n",
    "\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        print(f\"loading model from {filepath}...\")\n",
    "#         print(checkpoint[key])\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def save_model(self, saves: str):\n",
    "        print(f\"Saving model...\")\n",
    "        state = {\n",
    "            'net': self.model.state_dict()\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        current_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "#                 for i, output in enumerate(outputs.tolist()):\n",
    "#                     if targets[i,0].tolist() == round(output[0]):\n",
    "#                         correct += 1\n",
    "\n",
    "#             train_acc = round(100*correct/total, 4)\n",
    "#             train_accs.append(train_acc)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d69d25f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 87.094\n",
      "Saving after new best accuracy : 87.245\n",
      "Saving after new best accuracy : 87.396\n",
      "Saving after new best accuracy : 87.472\n",
      "Saving after new best accuracy : 87.547\n",
      "-- Epoch 50, Train Loss : 0.4537103418260813, Test Loss : 0.47308585047721863\n",
      "Saving after new best accuracy : 87.623\n",
      "-- Epoch 100, Train Loss : 0.4282282181084156, Test Loss : 0.4734671711921692\n",
      "-- Epoch 150, Train Loss : 0.44628280587494373, Test Loss : 0.46076470613479614\n",
      "-- Epoch 200, Train Loss : 0.41700588166713715, Test Loss : 0.4638032913208008\n",
      "Saving after new best accuracy : 87.698\n",
      "-- Epoch 250, Train Loss : 0.4403898511081934, Test Loss : 0.4543912708759308\n",
      "-- Epoch 300, Train Loss : 0.40898437425494194, Test Loss : 0.46788427233695984\n",
      "-- Epoch 350, Train Loss : 0.39894199557602406, Test Loss : 0.46354949474334717\n",
      "-- Epoch 400, Train Loss : 0.42502484284341335, Test Loss : 0.45785975456237793\n",
      "-- Epoch 450, Train Loss : 0.3994424734264612, Test Loss : 0.46880945563316345\n",
      "Saving after new best accuracy : 87.774\n",
      "-- Epoch 500, Train Loss : 0.42743949964642525, Test Loss : 0.45816662907600403\n",
      "-- Epoch 550, Train Loss : 0.42275407910346985, Test Loss : 0.46588894724845886\n",
      "-- Epoch 600, Train Loss : 0.4054960571229458, Test Loss : 0.46771517395973206\n",
      "-- Epoch 650, Train Loss : 0.40576811134815216, Test Loss : 0.46185633540153503\n",
      "-- Epoch 700, Train Loss : 0.41919977962970734, Test Loss : 0.46229350566864014\n",
      "-- Epoch 750, Train Loss : 0.42207295075058937, Test Loss : 0.4777846336364746\n",
      "-- Epoch 800, Train Loss : 0.41772380471229553, Test Loss : 0.4665132462978363\n",
      "-- Epoch 850, Train Loss : 0.39887136593461037, Test Loss : 0.47843214869499207\n",
      "-- Epoch 900, Train Loss : 0.4161521140486002, Test Loss : 0.47452792525291443\n",
      "-- Epoch 950, Train Loss : 0.41582194715738297, Test Loss : 0.46708953380584717\n",
      "-- Epoch 1000, Train Loss : 0.43235586024820805, Test Loss : 0.47062554955482483\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 90.6 seconds\n",
      "loading model from ../../data/models/Phemernr1-RNR_4LayerNet_L2Reg_RoBERTa_Finetuned.pth...\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1325])\n",
      "1325 vs 1325\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 80.508 %\n",
      "- Recall : 84.444 %\n",
      "- F1 : 0.8243\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 91.794 %\n",
      "- Recall : 89.486 %\n",
      "- F1 : 0.90625\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 87.774 %\n",
      "- Precision : 86.151 %\n",
      "- Recall : 86.965 %\n",
      "- F1 : 0.86556\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Phemernr1-RNR_4LayerNet_L2Reg_RoBERTa_Finetuned Validation, 87.774, 86.151, 86.965, 0.86556, 80.508, 84.444, 0.8243, 91.794, 89.486, 0.90625, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([575])\n",
      "575 vs 575\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 83.168 %\n",
      "- Recall : 83.168 %\n",
      "- F1 : 0.83168\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 90.885 %\n",
      "- Recall : 90.885 %\n",
      "- F1 : 0.90885\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 88.174 %\n",
      "- Precision : 87.027 %\n",
      "- Recall : 87.027 %\n",
      "- F1 : 0.87027\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Phemernr1-RNR_4LayerNet_L2Reg_RoBERTa_Finetuned Test, 88.174, 87.027, 87.027, 0.87027, 83.168, 83.168, 0.83168, 90.885, 90.885, 0.90885, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_L2Reg_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=2, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc76bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
