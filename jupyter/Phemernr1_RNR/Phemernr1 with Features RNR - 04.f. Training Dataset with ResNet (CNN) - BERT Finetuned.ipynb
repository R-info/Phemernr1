{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr1_wF-RNR\"\n",
    "unique_name = \"BERT_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5802, 928)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr1_with_features-RNR_BERT_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "first = vectors[0]\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOMBSHELL: #Ferguson chief says the police off...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It appears that #Ferguson PD are trying to ass...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All weekend ppl will be talking about the \"rob...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why would the officer tell #MikeBrown to get o...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael Brown is the 17 yr old boy who was sho...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>training</td>\n",
       "      <td>0</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text     topic    label  \\\n",
       "0  BOMBSHELL: #Ferguson chief says the police off...  ferguson  rumours   \n",
       "1  It appears that #Ferguson PD are trying to ass...  ferguson  rumours   \n",
       "2  All weekend ppl will be talking about the \"rob...  ferguson  rumours   \n",
       "3  Why would the officer tell #MikeBrown to get o...  ferguson  rumours   \n",
       "4  Michael Brown is the 17 yr old boy who was sho...  ferguson  rumours   \n",
       "\n",
       "        tvt  cv_fold        tvt2  \n",
       "0      test        3  validation  \n",
       "1  training        1    training  \n",
       "2      test        3  validation  \n",
       "3      test        3    training  \n",
       "4  training        0    training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr1_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4698ab17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "maritime-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] == \"rumours\":\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quality-burst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3911, 928)\n",
      "(1322, 928)\n",
      "(569, 928)\n",
      "(3911,)\n",
      "(1322,)\n",
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e860c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = self.bn2(self.lin2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.lin3 = nn.Linear(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = F.leaky_relu(self.bn2(self.lin2(out)), 0.1)\n",
    "        out = self.bn3(self.lin3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, n_input=768, num_classes=1):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 512\n",
    "\n",
    "        self.lin1 = nn.Linear(n_input, self.in_planes)\n",
    "        self.bn1 = nn.BatchNorm1d(self.in_planes)\n",
    "        self.layer1 = self._make_layer(block, 512, num_blocks[0])\n",
    "        self.layer2 = self._make_layer(block, 256, num_blocks[1])\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2])\n",
    "        self.layer4 = self._make_layer(block, 64, num_blocks[3])\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks):\n",
    "        strides = [1] * num_blocks\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet10(n_input=768, n_output=1, block=BasicBlock):\n",
    "    return ResNet(block, [1, 1, 1, 1], n_input, n_output)\n",
    "\n",
    "    \n",
    "def ResNet18(n_input=768, n_output=1, block=BasicBlock):\n",
    "    return ResNet(block, [2, 2, 2, 2], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet34(n_input=768, n_output=1, block=BasicBlock):\n",
    "    return ResNet(block, [3, 4, 6, 3], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet50(n_input=768, n_output=1, block=Bottleneck):\n",
    "    return ResNet(block, [3, 4, 6, 3], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet101(n_input=768, n_output=1, block=Bottleneck):\n",
    "    return ResNet(block, [3, 4, 23, 3], n_input, n_output)\n",
    "\n",
    "\n",
    "def ResNet152(n_input=768, n_output=1, block=Bottleneck):\n",
    "    return ResNet(block, [3, 8, 36, 3], n_input, n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e05091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNNBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(CNNBasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.conv1(x)), 0.1)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNBottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(CNNBottleneck, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.lin3 = nn.Linear(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = F.leaky_relu(self.bn2(self.lin2(out)), 0.1)\n",
    "        out = self.bn3(self.lin3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=1):\n",
    "        super(CNNResNet, self).__init__()\n",
    "        self.in_planes = 24\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 24, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(24)\n",
    "        self.layer1 = self._make_layer(block, 24, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 48, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 64, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(64 * 29 * 32, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.conv1(x)), 0.1)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def CNNResNet10(n_output: int):\n",
    "    return CNNResNet(CNNBasicBlock, [1, 1, 1, 1], n_output)\n",
    "\n",
    "    \n",
    "def CNNResNet18(n_output: int):\n",
    "    return CNNResNet(CNNBasicBlock, [2, 2, 2, 2], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet34(n_output: int):\n",
    "    return CNNResNet(CNNBasicBlock, [3, 4, 6, 3], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet50(n_output: int):\n",
    "    return CNNResNet(CNNBottleneck, [3, 4, 6, 3], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet101(n_output: int):\n",
    "    return CNNResNet(CNNBottleneck, [3, 4, 23, 3], n_output)\n",
    "\n",
    "\n",
    "def CNNResNet152(n_output: int):\n",
    "    return CNNResNet(CNNBottleneck, [3, 8, 36, 3], n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        model,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        n_features: int = 4,\n",
    "        lr: float = 0.0002,\n",
    "        beta1: float = 0.5,\n",
    "        device: str = None,\n",
    "        model_type: str = \"mlp\"\n",
    "    ):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.model = model\n",
    "        self.model_type = model_type\n",
    "        self.criterion = criterion()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.model(input)\n",
    "        return x\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def save_model(self, saves: str):\n",
    "        print(f\"Saving model...\")\n",
    "        state = {\n",
    "            'net': self.model.state_dict()\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        current_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "\n",
    "                if self.model_type == \"cnn\":\n",
    "                    outputs = self.model(inputs.unsqueeze(1))\n",
    "                elif self.model_type == \"mlp\":\n",
    "                    outputs = self.model(inputs)\n",
    "\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "#                 for i, output in enumerate(outputs.tolist()):\n",
    "#                     if targets[i,0].tolist() == round(output[0]):\n",
    "#                         correct += 1\n",
    "\n",
    "#             train_acc = round(100*correct/total, 4)\n",
    "#             train_accs.append(train_acc)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                \n",
    "                if self.model_type == 'mlp':\n",
    "                    outputs = self.model(inputs)\n",
    "                else:\n",
    "                    outputs = self.model(inputs.unsqueeze(1))\n",
    "\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                if self.model_type == 'mlp':\n",
    "                    preds = self.predict(test_x)\n",
    "                else:\n",
    "                    preds = self.predict(test_x.reshape(test_x.shape[0], 1, 29, 32))\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61ccef0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Phemernr1_wF-RNR_ResNet10_CNN_BERT_Finetuned\n",
      "Using cuda\n",
      "Saving after new best accuracy : 34.039\n",
      "Saving after new best accuracy : 76.475\n",
      "Saving after new best accuracy : 87.141\n",
      "Saving after new best accuracy : 88.502\n",
      "Saving after new best accuracy : 88.729\n",
      "Saving after new best accuracy : 88.88\n",
      "-- Epoch 50, Train Loss : 0.0008434137480435311, Test Loss : 1.1476292610168457\n",
      "-- Epoch 100, Train Loss : 0.0002714076363190543, Test Loss : 1.2285054922103882\n",
      "-- Epoch 150, Train Loss : 0.00013602278886537533, Test Loss : 1.279302716255188\n",
      "-- Epoch 200, Train Loss : 8.218546281568706e-05, Test Loss : 1.31684148311615\n",
      "-- Epoch 250, Train Loss : 5.509288382654631e-05, Test Loss : 1.346879005432129\n",
      "-- Epoch 300, Train Loss : 3.9381413898809114e-05, Test Loss : 1.3724150657653809\n",
      "-- Epoch 350, Train Loss : 2.942261005500768e-05, Test Loss : 1.3948053121566772\n",
      "-- Epoch 400, Train Loss : 2.269922273967495e-05, Test Loss : 1.4148151874542236\n",
      "-- Epoch 450, Train Loss : 1.7951599460275247e-05, Test Loss : 1.4330428838729858\n",
      "-- Epoch 500, Train Loss : 1.4476652751227448e-05, Test Loss : 1.4498671293258667\n",
      "-- Epoch 550, Train Loss : 1.1860318181788898e-05, Test Loss : 1.465564489364624\n",
      "-- Epoch 600, Train Loss : 9.831046682506894e-06, Test Loss : 1.4803823232650757\n",
      "-- Epoch 650, Train Loss : 8.229604191001272e-06, Test Loss : 1.4944260120391846\n",
      "-- Epoch 700, Train Loss : 6.947133613266487e-06, Test Loss : 1.5078580379486084\n",
      "-- Epoch 750, Train Loss : 5.907900188617532e-06, Test Loss : 1.520802617073059\n",
      "-- Epoch 800, Train Loss : 5.055428019318242e-06, Test Loss : 1.53328275680542\n",
      "-- Epoch 850, Train Loss : 4.35069574677982e-06, Test Loss : 1.5453970432281494\n",
      "-- Epoch 900, Train Loss : 3.760731758006841e-06, Test Loss : 1.557185411453247\n",
      "-- Epoch 950, Train Loss : 3.2648067076479492e-06, Test Loss : 1.5686737298965454\n",
      "Saving after new best accuracy : 88.956\n",
      "-- Epoch 1000, Train Loss : 2.8441327089012702e-06, Test Loss : 1.5799351930618286\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 702.6 seconds\n",
      "\n",
      "---- Validation Set ----\n",
      "Predictions : torch.Size([1322])\n",
      "1322 vs 1322\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 86.19 %\n",
      "- Recall : 80.444 %\n",
      "- F1 : 0.83218\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 90.244 %\n",
      "- Recall : 93.349 %\n",
      "- F1 : 0.9177\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 88.956 %\n",
      "- Precision : 88.217 %\n",
      "- Recall : 86.897 %\n",
      "- F1 : 0.87552\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Phemernr1_wF-RNR_ResNet10_CNN_BERT_Finetuned Validation, 88.956, 88.217, 86.897, 0.87552, 86.19, 80.444, 0.83218, 90.244, 93.349, 0.9177, \n",
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([569])\n",
      "569 vs 569\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 81.622 %\n",
      "- Recall : 77.835 %\n",
      "- F1 : 0.79683\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 88.802 %\n",
      "- Recall : 90.933 %\n",
      "- F1 : 0.89855\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 86.467 %\n",
      "- Precision : 85.212 %\n",
      "- Recall : 84.384 %\n",
      "- F1 : 0.84796\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Phemernr1_wF-RNR_ResNet10_CNN_BERT_Finetuned Test, 86.467, 85.212, 84.384, 0.84796, 81.622, 77.835, 0.79683, 88.802, 90.933, 0.89855, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"{dataset_name}_ResNet10_CNN_{unique_name}\"\n",
    "start = time.time()\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(CNNResNet10(n_output=4), train_vectors.shape[1], n_output=2, criterion=nn.CrossEntropyLoss, n_features=16, model_type=\"cnn\") #, device=\"cpu\")\n",
    "model.train_eval(torch.Tensor(train_vectors.reshape(train_vectors.shape[0], 29, 32)),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors.reshape(val_vectors.shape[0], 29, 32)),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=1024)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Validation Set ----\")\n",
    "preds = model.predict(val_vectors.reshape(val_vectors.shape[0], 1, 29, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors.reshape(test_vectors.shape[0], 1, 29, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c746093f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Phemernr1_wF-RNR_ResNet18_CNN_BERT_Finetuned\n",
      "Using cuda\n",
      "Saving after new best accuracy : 34.039\n",
      "Saving after new best accuracy : 74.735\n",
      "Saving after new best accuracy : 88.578\n",
      "Saving after new best accuracy : 88.654\n",
      "Saving after new best accuracy : 89.032\n",
      "-- Epoch 50, Train Loss : 0.00021718198468079208, Test Loss : 1.35611093044281\n",
      "-- Epoch 100, Train Loss : 7.176112538331836e-05, Test Loss : 1.4168953895568848\n",
      "-- Epoch 150, Train Loss : 3.606875698380918e-05, Test Loss : 1.4572911262512207\n",
      "-- Epoch 200, Train Loss : 2.1524328062128006e-05, Test Loss : 1.4885576963424683\n",
      "-- Epoch 250, Train Loss : 1.4083219284088955e-05, Test Loss : 1.5147678852081299\n",
      "-- Epoch 300, Train Loss : 9.764403721135295e-06, Test Loss : 1.5378491878509521\n",
      "-- Epoch 350, Train Loss : 7.035229085516903e-06, Test Loss : 1.5588244199752808\n",
      "-- Epoch 400, Train Loss : 5.206272131630385e-06, Test Loss : 1.5782718658447266\n",
      "-- Epoch 450, Train Loss : 3.933243196030389e-06, Test Loss : 1.5966776609420776\n",
      "-- Epoch 500, Train Loss : 3.01275280811808e-06, Test Loss : 1.6143122911453247\n",
      "-- Epoch 550, Train Loss : 2.3354042415490994e-06, Test Loss : 1.6313509941101074\n",
      "-- Epoch 600, Train Loss : 1.8272861392887307e-06, Test Loss : 1.6479697227478027\n",
      "-- Epoch 650, Train Loss : 1.4374057588639744e-06, Test Loss : 1.6643365621566772\n",
      "-- Epoch 700, Train Loss : 1.139630128044189e-06, Test Loss : 1.6805329322814941\n",
      "-- Epoch 750, Train Loss : 9.054344145553728e-07, Test Loss : 1.6965852975845337\n",
      "-- Epoch 800, Train Loss : 7.218735320613234e-07, Test Loss : 1.7125076055526733\n",
      "-- Epoch 850, Train Loss : 5.771232367557388e-07, Test Loss : 1.728386402130127\n",
      "-- Epoch 900, Train Loss : 4.615982509559302e-07, Test Loss : 1.7443326711654663\n",
      "-- Epoch 950, Train Loss : 3.718157040033532e-07, Test Loss : 1.7603113651275635\n",
      "-- Epoch 1000, Train Loss : 2.967623702332389e-07, Test Loss : 1.7762541770935059\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 1291.33 seconds\n",
      "\n",
      "---- Validation Set ----\n",
      "Predictions : torch.Size([1322])\n",
      "1322 vs 1322\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 85.219 %\n",
      "- Recall : 82.0 %\n",
      "- F1 : 0.83579\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 90.889 %\n",
      "- Recall : 92.661 %\n",
      "- F1 : 0.91766\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 89.032 %\n",
      "- Precision : 88.054 %\n",
      "- Recall : 87.33 %\n",
      "- F1 : 0.87691\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Phemernr1_wF-RNR_ResNet18_CNN_BERT_Finetuned Validation, 89.032, 88.054, 87.33, 0.87691, 85.219, 82.0, 0.83579, 90.889, 92.661, 0.91766, \n",
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([569])\n",
      "569 vs 569\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 80.729 %\n",
      "- Recall : 79.897 %\n",
      "- F1 : 0.80311\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 89.655 %\n",
      "- Recall : 90.133 %\n",
      "- F1 : 0.89894\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 86.643 %\n",
      "- Precision : 85.192 %\n",
      "- Recall : 85.015 %\n",
      "- F1 : 0.85103\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Phemernr1_wF-RNR_ResNet18_CNN_BERT_Finetuned Test, 86.643, 85.192, 85.015, 0.85103, 80.729, 79.897, 0.80311, 89.655, 90.133, 0.89894, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"{dataset_name}_ResNet18_CNN_{unique_name}\"\n",
    "start = time.time()\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(CNNResNet18(n_output=4), train_vectors.shape[1], n_output=2, criterion=nn.CrossEntropyLoss, n_features=16, model_type=\"cnn\") #, device=\"cpu\")\n",
    "model.train_eval(torch.Tensor(train_vectors.reshape(train_vectors.shape[0], 29, 32)),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors.reshape(val_vectors.shape[0], 29, 32)),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Validation Set ----\")\n",
    "preds = model.predict(val_vectors.reshape(val_vectors.shape[0], 1, 29, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors.reshape(test_vectors.shape[0], 1, 29, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d251e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
