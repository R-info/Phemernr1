{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr1-RNR\"\n",
    "unique_name = \"RoBERTa_Finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5802, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr1-RNR_RoBERTa_base_finetuned_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>cv_fold</th>\n",
       "      <th>tvt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOMBSHELL: #Ferguson chief says the police off...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It appears that #Ferguson PD are trying to ass...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All weekend ppl will be talking about the \"rob...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why would the officer tell #MikeBrown to get o...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael Brown is the 17 yr old boy who was sho...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>training</td>\n",
       "      <td>0</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text     topic    label  \\\n",
       "0  BOMBSHELL: #Ferguson chief says the police off...  ferguson  rumours   \n",
       "1  It appears that #Ferguson PD are trying to ass...  ferguson  rumours   \n",
       "2  All weekend ppl will be talking about the \"rob...  ferguson  rumours   \n",
       "3  Why would the officer tell #MikeBrown to get o...  ferguson  rumours   \n",
       "4  Michael Brown is the 17 yr old boy who was sho...  ferguson  rumours   \n",
       "\n",
       "        tvt  cv_fold        tvt2  \n",
       "0      test        3    training  \n",
       "1  training        1    training  \n",
       "2      test        3    training  \n",
       "3      test        3    training  \n",
       "4  training        0  validation  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed/phemernr1_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9dc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumour', 'non-rumour']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = ['rumour', 'non-rumour']\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, d in data.iterrows():\n",
    "#     lab = labels_str.index(d['label'])\n",
    "    if d['label'] == \"rumours\":\n",
    "        lab = 0\n",
    "    else:\n",
    "        lab = 1\n",
    "    labels.append(lab)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, d in data.iterrows() if d['tvt2'] == 'testting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3902, 768)\n",
      "(1325, 768)\n",
      "(575, 768)\n",
      "(3902,)\n",
      "(1325,)\n",
      "(575,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets.long())\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_y]),\n",
    "                    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds.cpu().numpy()]),\n",
    "                    binary=False\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(torch.Tensor(input_x))\n",
    "            preds = torch.log_softmax(preds, dim = 1)\n",
    "            _, preds = torch.max(preds, dim = 1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd07cc1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "Using cuda\n",
      "Saving after new best accuracy : 87.019\n",
      "Saving after new best accuracy : 87.094\n",
      "Saving after new best accuracy : 87.245\n",
      "Saving after new best accuracy : 87.396\n",
      "Saving after new best accuracy : 87.547\n",
      "Saving after new best accuracy : 87.623\n",
      "-- Epoch 50, Train Loss : 0.40972229838371277, Test Loss : 0.4643334448337555\n",
      "-- Epoch 100, Train Loss : 0.4067838918417692, Test Loss : 0.46637409925460815\n",
      "-- Epoch 150, Train Loss : 0.4028105530887842, Test Loss : 0.47136858105659485\n",
      "Saving after new best accuracy : 87.698\n",
      "Saving after new best accuracy : 87.774\n",
      "-- Epoch 200, Train Loss : 0.3993378411978483, Test Loss : 0.4804154634475708\n",
      "-- Epoch 250, Train Loss : 0.39700066670775414, Test Loss : 0.48880329728126526\n",
      "-- Epoch 300, Train Loss : 0.39468864165246487, Test Loss : 0.4970172047615051\n",
      "-- Epoch 350, Train Loss : 0.392644552513957, Test Loss : 0.5056885480880737\n",
      "-- Epoch 400, Train Loss : 0.39042846113443375, Test Loss : 0.5157210230827332\n",
      "-- Epoch 450, Train Loss : 0.38852826692163944, Test Loss : 0.52263343334198\n",
      "-- Epoch 500, Train Loss : 0.3865253869444132, Test Loss : 0.5449236035346985\n",
      "-- Epoch 550, Train Loss : 0.3830111473798752, Test Loss : 0.5712553858757019\n",
      "-- Epoch 600, Train Loss : 0.38219366036355495, Test Loss : 0.5857478976249695\n",
      "-- Epoch 650, Train Loss : 0.38261465914547443, Test Loss : 0.6043396592140198\n",
      "-- Epoch 700, Train Loss : 0.3799557238817215, Test Loss : 0.6215575337409973\n",
      "-- Epoch 750, Train Loss : 0.3831733465194702, Test Loss : 0.5528073310852051\n",
      "-- Epoch 800, Train Loss : 0.3791812136769295, Test Loss : 0.5716866254806519\n",
      "-- Epoch 850, Train Loss : 0.3754972144961357, Test Loss : 0.5852561593055725\n",
      "-- Epoch 900, Train Loss : 0.3746226318180561, Test Loss : 0.6032618284225464\n",
      "-- Epoch 950, Train Loss : 0.37251476012170315, Test Loss : 0.6201878786087036\n",
      "-- Epoch 1000, Train Loss : 0.37239434011280537, Test Loss : 0.6370965242385864\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time : 125.7 seconds\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1325])\n",
      "1325 vs 1325\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 80.901 %\n",
      "- Recall : 83.778 %\n",
      "- F1 : 0.82314\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 91.502 %\n",
      "- Recall : 89.829 %\n",
      "- F1 : 0.90657\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 87.774 %\n",
      "- Precision : 86.202 %\n",
      "- Recall : 86.803 %\n",
      "- F1 : 0.86501\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Phemernr1-RNR_4LayerNet_RoBERTa_Finetuned Validation, 87.774, 86.202, 86.803, 0.86501, 80.901, 83.778, 0.82314, 91.502, 89.829, 0.90657, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([575])\n",
      "575 vs 575\n",
      "Multi Class Evaluation\n",
      "\n",
      "Class rumour Evaluation\n",
      "- Precision : 83.333 %\n",
      "- Recall : 81.683 %\n",
      "- F1 : 0.825\n",
      "\n",
      "Class non-rumour Evaluation\n",
      "- Precision : 90.186 %\n",
      "- Recall : 91.153 %\n",
      "- F1 : 0.90667\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 87.826 %\n",
      "- Precision : 86.76 %\n",
      "- Recall : 86.418 %\n",
      "- F1 : 0.86589\n",
      "\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,rumour,,,non-rumour,,,\n",
      "Phemernr1-RNR_4LayerNet_RoBERTa_Finetuned Test, 87.826, 86.76, 86.418, 0.86589, 83.333, 81.683, 0.825, 90.186, 91.153, 0.90667, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "start = time.time()\n",
    "model_name = f\"{dataset_name}_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], n_output=2, criterion=nn.CrossEntropyLoss)\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=512)\n",
    "print(f\"Exec Time : {round(time.time() - start, 2)} seconds\")\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in val_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Validation\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=np.array([[1 if j == v else 0 for j in range(len(labels_str))] for v in test_labels]),\n",
    "    predictions=np.array([[1 if j == p else 0 for j in range(len(labels_str))] for p in preds]),\n",
    "    binary=False,\n",
    "    model_name=f\"{model_name} Test\"\n",
    ")\n",
    "conf_mat.evaluate(classes=labels_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55461251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
