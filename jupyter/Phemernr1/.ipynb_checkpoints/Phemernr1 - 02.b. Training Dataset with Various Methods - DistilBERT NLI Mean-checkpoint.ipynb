{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "random.seed(33)\n",
    "\n",
    "unique_name = \"DistilBERT_NLI_Mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5802, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr1_DistilBERT_NLI_Mean_vectors.txt\", delimiter=\",\")\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOMBSHELL: #Ferguson chief says the police off...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It appears that #Ferguson PD are trying to ass...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All weekend ppl will be talking about the \"rob...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why would the officer tell #MikeBrown to get o...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael Brown is the 17 yr old boy who was sho...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text     topic    label  \\\n",
       "0  BOMBSHELL: #Ferguson chief says the police off...  ferguson  rumours   \n",
       "1  It appears that #Ferguson PD are trying to ass...  ferguson  rumours   \n",
       "2  All weekend ppl will be talking about the \"rob...  ferguson  rumours   \n",
       "3  Why would the officer tell #MikeBrown to get o...  ferguson  rumours   \n",
       "4  Michael Brown is the 17 yr old boy who was sho...  ferguson  rumours   \n",
       "\n",
       "        tvt  \n",
       "0      test  \n",
       "1  training  \n",
       "2      test  \n",
       "3      test  \n",
       "4  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phemernr2 = pd.read_csv(\"../../data/processed/phemernr1_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "phemernr2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f469a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [0], [0], [0], [0], [0], [0], [0], [0], [0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, p2 in phemernr2.iterrows():\n",
    "    if p2['label'] == 'rumours':\n",
    "        labels.append([0])\n",
    "    elif p2['label'] == 'non-rumours':\n",
    "        labels.append([1])\n",
    "    else:\n",
    "        labels.append(None)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, p2 in phemernr2.iterrows() if p2['tvt'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, p2 in phemernr2.iterrows() if p2['tvt'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, p2 in phemernr2.iterrows() if p2['tvt'] == 'test'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, p2 in phemernr2.iterrows() if p2['tvt'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, p2 in phemernr2.iterrows() if p2['tvt'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, p2 in phemernr2.iterrows() if p2['tvt'] == 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "increasing-plymouth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumours', 'non-rumours']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_tag = ['rumours', 'non-rumours']\n",
    "label_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demanding-consortium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3498, 768)\n",
      "(1150, 768)\n",
      "(1154, 768)\n",
      "(3498, 1)\n",
      "(1150, 1)\n",
      "(1154, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0da6df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([1175, 2323]))\n",
      "(array([0, 1]), array([416, 734]))\n",
      "(array([0, 1]), array([381, 773]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(train_labels, return_counts=True))\n",
    "print(np.unique(val_labels, return_counts=True))\n",
    "print(np.unique(test_labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class NNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        beta1: float = 0.5,\n",
    "        lr: float = 0.0002,\n",
    "        device: str = None\n",
    "    ):\n",
    "        super(NNClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.criterion = criterion()\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        best_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                try:\n",
    "                    loss = self.criterion(outputs, targets)\n",
    "                except Exception:\n",
    "                    loss = self.criterion(outputs, targets.long())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "                \n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                preds = self.predict(test_x)\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=test_y,\n",
    "                    predictions=[p[0] for p in preds.cpu().numpy()],\n",
    "                    binary=True\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.model(torch.Tensor(input_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce67903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LOGISTIC REGRESSION ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> execution time : 2.16 seconds\n",
      "Validation Set\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 641\n",
      "False Positive : 88\n",
      "False Negative : 93\n",
      "True Negative : 328\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 87.929 %\n",
      "- Recall : 87.33 %\n",
      "- F1 : 0.87628\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 77.91 %\n",
      "- Recall : 78.846 %\n",
      "- F1 : 0.78375\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.261 %\n",
      "- Precision : 82.919 %\n",
      "- Recall : 83.088 %\n",
      "- F1 : 0.83003\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 84.261, 82.919, 83.088, 0.83003, 87.929, 87.33, 0.87628, 77.91, 78.846, 0.78375, \n",
      "Test Set\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 678\n",
      "False Positive : 92\n",
      "False Negative : 95\n",
      "True Negative : 289\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 88.052 %\n",
      "- Recall : 87.71 %\n",
      "- F1 : 0.87881\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 75.26 %\n",
      "- Recall : 75.853 %\n",
      "- F1 : 0.75556\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 83.795 %\n",
      "- Precision : 81.656 %\n",
      "- Recall : 81.782 %\n",
      "- F1 : 0.81719\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 83.795, 81.656, 81.782, 0.81719, 88.052, 87.71, 0.87881, 75.26, 75.853, 0.75556, \n",
      "--- END ---\n",
      "\n",
      "\n",
      "--- K-NEAREST NEIGHBOR ---\n",
      "---> execution time : 0.0 seconds\n",
      "Validation Set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 614\n",
      "False Positive : 88\n",
      "False Negative : 120\n",
      "True Negative : 328\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 87.464 %\n",
      "- Recall : 83.651 %\n",
      "- F1 : 0.85515\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 73.214 %\n",
      "- Recall : 78.846 %\n",
      "- F1 : 0.75926\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 81.913 %\n",
      "- Precision : 80.339 %\n",
      "- Recall : 81.249 %\n",
      "- F1 : 0.80791\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 81.913, 80.339, 81.249, 0.80791, 87.464, 83.651, 0.85515, 73.214, 78.846, 0.75926, \n",
      "Test Set\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 647\n",
      "False Positive : 78\n",
      "False Negative : 126\n",
      "True Negative : 303\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 89.241 %\n",
      "- Recall : 83.7 %\n",
      "- F1 : 0.86382\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 70.629 %\n",
      "- Recall : 79.528 %\n",
      "- F1 : 0.74815\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 82.322 %\n",
      "- Precision : 79.935 %\n",
      "- Recall : 81.614 %\n",
      "- F1 : 0.80766\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 82.322, 79.935, 81.614, 0.80766, 89.241, 83.7, 0.86382, 70.629, 79.528, 0.74815, \n",
      "--- END ---\n",
      "\n",
      "\n",
      "--- SUPPORT VECTOR MACHINE ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> execution time : 3.89 seconds\n",
      "Validation Set\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 647\n",
      "False Positive : 116\n",
      "False Negative : 87\n",
      "True Negative : 300\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 84.797 %\n",
      "- Recall : 88.147 %\n",
      "- F1 : 0.8644\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 77.519 %\n",
      "- Recall : 72.115 %\n",
      "- F1 : 0.7472\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 82.348 %\n",
      "- Precision : 81.158 %\n",
      "- Recall : 80.131 %\n",
      "- F1 : 0.80641\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 82.348, 81.158, 80.131, 0.80641, 84.797, 88.147, 0.8644, 77.519, 72.115, 0.7472, \n",
      "Test Set\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 674\n",
      "False Positive : 107\n",
      "False Negative : 99\n",
      "True Negative : 274\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 86.3 %\n",
      "- Recall : 87.193 %\n",
      "- F1 : 0.86744\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 73.458 %\n",
      "- Recall : 71.916 %\n",
      "- F1 : 0.72679\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 82.149 %\n",
      "- Precision : 79.879 %\n",
      "- Recall : 79.554 %\n",
      "- F1 : 0.79716\n",
      "- Average Confidence : 100.0 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Anonymous, 82.149, 79.879, 79.554, 0.79716, 86.3, 87.193, 0.86744, 73.458, 71.916, 0.72679, \n",
      "--- END ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage/Work/DataScience/.venv/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from library.classification import SKLearnClassification\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "dataset_name = \"Phemernr1\"\n",
    "\n",
    "logres_model = LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr', max_iter=10000)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "svm = LinearSVC()\n",
    "\n",
    "models = [\n",
    "    SKLearnClassification(logres_model, \"Logistic Regression\"),\n",
    "    SKLearnClassification(neigh, \"K-Nearest Neighbor\"),\n",
    "    SKLearnClassification(svm, \"Support Vector Machine\"),\n",
    "]\n",
    "for model in models:\n",
    "    print(f\"\\n--- {model.model_name.upper()} ---\")\n",
    "    model.train(train_vectors, train_labels, dataset_name)\n",
    "    \n",
    "    print(\"Validation Set\")\n",
    "    preds = model.predict(val_vectors)\n",
    "\n",
    "    conf_mat = ConfusionMatrix(\n",
    "        labels=val_labels,\n",
    "        predictions=preds,\n",
    "        binary=True\n",
    "    )\n",
    "    conf_mat.evaluate()\n",
    "    \n",
    "    print(\"Test Set\")\n",
    "    preds = model.predict(test_vectors)\n",
    "\n",
    "    conf_mat = ConfusionMatrix(\n",
    "        labels=test_labels,\n",
    "        predictions=preds,\n",
    "        binary=True\n",
    "    )\n",
    "    conf_mat.evaluate()\n",
    "\n",
    "    print(\"--- END ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd07cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification using 4-Layer Linear Network\n",
      "\n",
      "Validation Set\n",
      "Predictions : torch.Size([1150, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 679\n",
      "False Positive : 120\n",
      "False Negative : 55\n",
      "True Negative : 296\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 84.981 %\n",
      "- Recall : 92.507 %\n",
      "- F1 : 0.88584\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 84.33 %\n",
      "- Recall : 71.154 %\n",
      "- F1 : 0.77184\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.783 %\n",
      "- Precision : 84.656 %\n",
      "- Recall : 81.83 %\n",
      "- F1 : 0.83219\n",
      "- Average Confidence : 83.65 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Phemernr1_4LayerNet_DistilBERT_NLI_Mean, 84.783, 84.656, 81.83, 0.83219, 84.981, 92.507, 0.88584, 84.33, 71.154, 0.77184, \n",
      "\n",
      "Test Set\n",
      "Predictions : torch.Size([1154, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 722\n",
      "False Positive : 130\n",
      "False Negative : 51\n",
      "True Negative : 251\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 84.742 %\n",
      "- Recall : 93.402 %\n",
      "- F1 : 0.88862\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 83.113 %\n",
      "- Recall : 65.879 %\n",
      "- F1 : 0.73499\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 84.315 %\n",
      "- Precision : 83.927 %\n",
      "- Recall : 79.641 %\n",
      "- F1 : 0.81728\n",
      "- Average Confidence : 83.58 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Phemernr1_4LayerNet_DistilBERT_NLI_Mean, 84.315, 83.927, 79.641, 0.81728, 84.742, 93.402, 0.88862, 83.113, 65.879, 0.73499, \n"
     ]
    }
   ],
   "source": [
    "print(\"Multiclass Classification using 4-Layer Linear Network\")\n",
    "model_name = f\"Phemernr1_4LayerNet_{unique_name}\"\n",
    "model = NNClassifier(train_vectors.shape[1], criterion=nn.BCELoss)\n",
    "# model.train_eval(torch.Tensor(train_vectors),\n",
    "#                 torch.Tensor(train_labels),\n",
    "#                 torch.Tensor(val_vectors),\n",
    "#                 torch.Tensor(val_labels),\n",
    "#                 saves=model_name,\n",
    "#                 n_iter=1000,\n",
    "#                 batch_size=256)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\nValidation Set\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=val_labels,\n",
    "    predictions=[p[0] for p in preds],\n",
    "    binary=True,\n",
    "    model_name=model_name\n",
    ")\n",
    "conf_mat.evaluate()\n",
    "\n",
    "print(\"\\nTest Set\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=test_labels,\n",
    "    predictions=[p[0] for p in preds],\n",
    "    binary=True,\n",
    "    model_name=model_name\n",
    ")\n",
    "conf_mat.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6df201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
