{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from library.evaluation import ConfusionMatrix\n",
    "\n",
    "random.seed(37)\n",
    "\n",
    "unique_name = \"DistilBERT_NLI_Mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "loaded-organic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5802, 768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = np.loadtxt(\"../../data/processed/vectors/Phemernr1_DistilBERT_NLI_Mean_vectors.txt\", delimiter=\",\")\n",
    "first = vectors[0]\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOMBSHELL: #Ferguson chief says the police off...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It appears that #Ferguson PD are trying to ass...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All weekend ppl will be talking about the \"rob...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why would the officer tell #MikeBrown to get o...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael Brown is the 17 yr old boy who was sho...</td>\n",
       "      <td>ferguson</td>\n",
       "      <td>rumours</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text     topic    label  \\\n",
       "0  BOMBSHELL: #Ferguson chief says the police off...  ferguson  rumours   \n",
       "1  It appears that #Ferguson PD are trying to ass...  ferguson  rumours   \n",
       "2  All weekend ppl will be talking about the \"rob...  ferguson  rumours   \n",
       "3  Why would the officer tell #MikeBrown to get o...  ferguson  rumours   \n",
       "4  Michael Brown is the 17 yr old boy who was sho...  ferguson  rumours   \n",
       "\n",
       "        tvt  \n",
       "0      test  \n",
       "1  training  \n",
       "2      test  \n",
       "3      test  \n",
       "4  training  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phemernr = pd.read_csv(\"../../data/processed/phemernr1_dataset_with_tvt.csv\", lineterminator=\"\\n\")\n",
    "phemernr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "maritime-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [0], [0], [0], [0], [0], [0], [0], [0], [0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, p2 in phemernr.iterrows():\n",
    "    if p2['label'] == 'rumours':\n",
    "        labels.append([0])\n",
    "    elif p2['label'] == 'non-rumours':\n",
    "        labels.append([1])\n",
    "    else:\n",
    "        labels.append(None)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adverse-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = np.array([vectors[i] for i, p2 in phemernr.iterrows() if p2['tvt'] == 'training'])\n",
    "val_vectors = np.array([vectors[i] for i, p2 in phemernr.iterrows() if p2['tvt'] == 'validation'])\n",
    "test_vectors = np.array([vectors[i] for i, p2 in phemernr.iterrows() if p2['tvt'] == 'test'])\n",
    "\n",
    "train_labels = np.array([labels[i] for i, p2 in phemernr.iterrows() if p2['tvt'] == 'training'])\n",
    "val_labels = np.array([labels[i] for i, p2 in phemernr.iterrows() if p2['tvt'] == 'validation'])\n",
    "test_labels = np.array([labels[i] for i, p2 in phemernr.iterrows() if p2['tvt'] == 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "increasing-plymouth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumours', 'non-rumours']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_tag = ['rumours', 'non-rumours']\n",
    "label_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quality-burst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3498, 768)\n",
      "(1150, 768)\n",
      "(1154, 768)\n",
      "(3498, 1)\n",
      "(1150, 1)\n",
      "(1154, 1)\n",
      "Class 0 :  381\n",
      "Class 1 :  773\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(val_vectors.shape)\n",
    "print(test_vectors.shape)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(test_labels.shape)\n",
    "\n",
    "print(\"Class 0 : \", len([i for i in test_labels if i == 0]))\n",
    "print(\"Class 1 : \", len([i for i in test_labels if i == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "center-validity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([1175, 2323]))\n",
      "(array([0, 1]), array([416, 734]))\n",
      "(array([0, 1]), array([381, 773]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(train_labels, return_counts=True))\n",
    "print(np.unique(val_labels, return_counts=True))\n",
    "print(np.unique(test_labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e860c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = self.bn2(self.lin2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.lin3 = nn.Linear(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm1d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = F.leaky_relu(self.bn2(self.lin2(out)), 0.1)\n",
    "        out = self.bn3(self.lin3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, n_input=768, num_classes=1):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 512\n",
    "\n",
    "        self.lin1 = nn.Linear(n_input, self.in_planes)\n",
    "        self.bn1 = nn.BatchNorm1d(self.in_planes)\n",
    "        self.layer1 = self._make_layer(block, 512, num_blocks[0])\n",
    "        self.layer2 = self._make_layer(block, 256, num_blocks[1])\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2])\n",
    "        self.layer4 = self._make_layer(block, 64, num_blocks[3])\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "        self.final = nn.Sigmoid()\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks):\n",
    "        strides = [1] * num_blocks\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        out = self.final(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet10(n_input=768, block=BasicBlock):\n",
    "    return ResNet(block, [1, 1, 1, 1], n_input)\n",
    "\n",
    "    \n",
    "def ResNet18(n_input=768, block=BasicBlock):\n",
    "    return ResNet(block, [2, 2, 2, 2], n_input)\n",
    "\n",
    "\n",
    "def ResNet34(n_input=768, block=BasicBlock):\n",
    "    return ResNet(block, [3, 4, 6, 3], n_input)\n",
    "\n",
    "\n",
    "def ResNet50(n_input=768, block=Bottleneck):\n",
    "    return ResNet(block, [3, 4, 6, 3], n_input)\n",
    "\n",
    "\n",
    "def ResNet101(n_input=768, block=Bottleneck):\n",
    "    return ResNet(block, [3, 4, 23, 3], n_input)\n",
    "\n",
    "\n",
    "def ResNet152(n_input=768, block=Bottleneck):\n",
    "    return ResNet(block, [3, 8, 36, 3], n_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e05091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNNBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(CNNBasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.conv1(x)), 0.1)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNBottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes):\n",
    "        super(CNNBottleneck, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.lin2 = nn.Linear(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.lin3 = nn.Linear(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_planes, planes),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.lin1(x)), 0.1)\n",
    "        out = F.leaky_relu(self.bn2(self.lin2(out)), 0.1)\n",
    "        out = self.bn3(self.lin3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=1):\n",
    "        super(CNNResNet, self).__init__()\n",
    "        self.in_planes = 24\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 24, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(24)\n",
    "        self.layer1 = self._make_layer(block, 24, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 48, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 64, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(64 * 24 * 32, num_classes)\n",
    "        self.final = nn.Sigmoid()\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.bn1(self.conv1(x)), 0.1)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        out = self.final(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def CNNResNet10():\n",
    "    return CNNResNet(CNNBasicBlock, [1, 1, 1, 1])\n",
    "\n",
    "    \n",
    "def CNNResNet18():\n",
    "    return CNNResNet(CNNBasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def CNNResNet34():\n",
    "    return CNNResNet(CNNBasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def CNNResNet50():\n",
    "    return CNNResNet(CNNBottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def CNNResNet101():\n",
    "    return CNNResNet(CNNBottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def CNNResNet152():\n",
    "    return CNNResNet(CNNBottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "joint-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "        model,\n",
    "        n_input: int,\n",
    "        n_output: int = 1,\n",
    "        criterion: Callable = nn.BCELoss,\n",
    "        n_features: int = 4,\n",
    "        lr: float = 0.0002,\n",
    "        beta1: float = 0.5,\n",
    "        device: str = None,\n",
    "        model_type: str = \"mlp\"\n",
    "    ):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.model = model\n",
    "        self.model_type = model_type\n",
    "        self.criterion = criterion()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "        if not device or device not in ['cpu', 'cuda']:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        if self.device == 'cuda':\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "            cudnn.benchmark = True\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.model(input)\n",
    "        return x\n",
    "    \n",
    "    def load_pretrained(self, filepath: str, key: str = \"net\", is_parallel: bool = False):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        if is_parallel:\n",
    "            self.model = torch.nn.DataParallel(self.model)\n",
    "        self.model.load_state_dict(checkpoint[key], strict=False)\n",
    "    \n",
    "    def save_model(self, saves: str):\n",
    "        print(f\"Saving model...\")\n",
    "        state = {\n",
    "            'net': self.model.state_dict()\n",
    "        }\n",
    "        if not os.path.isdir('models'):\n",
    "            os.mkdir('models')\n",
    "        torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "    \n",
    "    def train_eval(self,\n",
    "        train_x, train_y,\n",
    "        test_x, test_y,\n",
    "        n_iter: int = 100,\n",
    "        batch_size: int = 128,\n",
    "        saves: str = None\n",
    "    ):\n",
    "        trainset = torch.utils.data.TensorDataset(train_x, train_y) # create your datset\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(test_x, test_y) # create your datset\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size) # create your dataloader\n",
    "\n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        test_accs = []\n",
    "        test_losses = []\n",
    "\n",
    "        print(f\"Using {self.device}\")\n",
    "        best_acc = 0\n",
    "        current_loss = 1000\n",
    "        best_test_acc = 0\n",
    "        epoch = 0\n",
    "        start_time = time.time()\n",
    "        results = {}\n",
    "        while True:\n",
    "            epoch += 1\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "                self.model.zero_grad()\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                if self.model_type == \"cnn\":\n",
    "                    outputs = self.model(inputs.unsqueeze(1))\n",
    "                elif self.model_type == \"mlp\":\n",
    "                    outputs = self.model(inputs)\n",
    "\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                total += targets.size(0)\n",
    "#                 for i, output in enumerate(outputs.tolist()):\n",
    "#                     if targets[i,0].tolist() == round(output[0]):\n",
    "#                         correct += 1\n",
    "\n",
    "#             train_acc = round(100*correct/total, 4)\n",
    "#             train_accs.append(train_acc)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            test_acc = 0\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = test_x.to(self.device), test_y.to(self.device)\n",
    "                \n",
    "                if self.model_type == 'mlp':\n",
    "                    outputs = self.model(inputs)\n",
    "                else:\n",
    "                    outputs = self.model(inputs.reshape(inputs.shape[0], 1, 24, 32))\n",
    "                \n",
    "                loss = self.criterion(outputs, targets)\n",
    "                try:\n",
    "                    outputs = self.model(inputs.unsqueeze(1))\n",
    "                except Exception:\n",
    "                    outputs = self.model(inputs)\n",
    "\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                if self.model_type == 'mlp':\n",
    "                    preds = self.predict(test_x)\n",
    "                else:\n",
    "                    preds = self.predict(test_x.reshape(test_x.shape[0], 1, 24, 32))\n",
    "                conf_mat = ConfusionMatrix(\n",
    "                    labels=test_y,\n",
    "                    predictions=[p[0] for p in preds.cpu().numpy()],\n",
    "                    binary=True\n",
    "                )\n",
    "                conf_mat.evaluate(logs=False)\n",
    "                test_acc = conf_mat.accuracy\n",
    "\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            if (epoch) % round(n_iter/20) == 0:\n",
    "                print(f\"-- Epoch {epoch}, Train Loss : {train_loss}, Test Loss : {test_loss}\")\n",
    "\n",
    "            # Save checkpoint.\n",
    "#             if saves and test_loss < best_loss:\n",
    "#                 print(f\"Saving after new best loss : {test_loss}\")\n",
    "#                 best_loss = test_loss\n",
    "            if saves and test_acc > best_test_acc:\n",
    "                print(f\"Saving after new best accuracy : {test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "\n",
    "                state = {\n",
    "                    'net': self.model.state_dict(),\n",
    "                }\n",
    "                if not os.path.isdir('models'):\n",
    "                    os.mkdir('models')\n",
    "                torch.save(state, f\"../../data/models/{saves}.pth\")\n",
    "            \n",
    "            if epoch >= n_iter:\n",
    "                break\n",
    "\n",
    "        # visualizing accuracy over epoch\n",
    "        fig, ax2 = plt.subplots(1)\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=1.5, wspace=0.4)\n",
    "\n",
    "        ax2.plot([i for i in range(len(train_losses))], train_losses, c='b', marker=\"o\", label='Train Loss')\n",
    "        ax2.plot([i for i in range(len(test_losses))], test_losses, c='r', marker=\"o\", label='Test Loss')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_xlim(0, len(train_losses))\n",
    "        ax2.set_ylim(min([min(train_losses), min(test_losses)])*0.1, max([max(train_losses), max(test_losses)]))\n",
    "        ax2.title.set_text(f\"Loss over time (epoch)\")\n",
    "        ax2.legend(loc='lower right')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.model(torch.Tensor(input_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1296e1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Phemernr1_ResNet10_MLP_DistilBERT_NLI_Mean\n",
      "Using cuda\n",
      "Saving after new best accuracy : 36.174\n",
      "Saving after new best accuracy : 36.783\n",
      "Saving after new best accuracy : 48.435\n",
      "Saving after new best accuracy : 58.261\n",
      "Saving after new best accuracy : 67.13\n",
      "Saving after new best accuracy : 67.739\n",
      "Saving after new best accuracy : 70.696\n",
      "Saving after new best accuracy : 73.565\n",
      "Saving after new best accuracy : 74.348\n",
      "Saving after new best accuracy : 75.739\n",
      "Saving after new best accuracy : 76.0\n",
      "Saving after new best accuracy : 76.087\n",
      "Saving after new best accuracy : 78.696\n",
      "-- Epoch 50, Train Loss : 0.36812038347125053, Test Loss : 0.5909073948860168\n",
      "-- Epoch 100, Train Loss : 0.14296713704243302, Test Loss : 0.6315289735794067\n",
      "-- Epoch 150, Train Loss : 0.08506668731570244, Test Loss : 0.6647590398788452\n",
      "-- Epoch 200, Train Loss : 0.057551456382498145, Test Loss : 0.7050941586494446\n",
      "Saving after new best accuracy : 78.87\n",
      "-- Epoch 250, Train Loss : 0.0396414203569293, Test Loss : 0.7431039214134216\n",
      "-- Epoch 300, Train Loss : 1.7796493470668793, Test Loss : 1.2469452619552612\n",
      "Saving after new best accuracy : 79.13\n",
      "-- Epoch 350, Train Loss : 0.04115221090614796, Test Loss : 0.7114397287368774\n",
      "-- Epoch 400, Train Loss : 0.026813978096470237, Test Loss : 0.7742943167686462\n",
      "-- Epoch 450, Train Loss : 0.02017598063685, Test Loss : 0.8126496076583862\n",
      "-- Epoch 500, Train Loss : 0.015906205226201564, Test Loss : 0.8498430252075195\n",
      "-- Epoch 550, Train Loss : 0.013398381706792861, Test Loss : 0.8744707703590393\n",
      "-- Epoch 600, Train Loss : 0.011075035785324872, Test Loss : 0.9038745164871216\n",
      "-- Epoch 650, Train Loss : 0.009287150140153244, Test Loss : 0.9376369714736938\n",
      "-- Epoch 700, Train Loss : 0.007941347328596748, Test Loss : 0.9685143828392029\n",
      "-- Epoch 750, Train Loss : 0.006852385442471132, Test Loss : 0.9966112375259399\n",
      "-- Epoch 800, Train Loss : 0.005943161464529112, Test Loss : 1.0222597122192383\n",
      "-- Epoch 850, Train Loss : 0.005176546314032748, Test Loss : 1.046138048171997\n",
      "-- Epoch 900, Train Loss : 0.004538960114587098, Test Loss : 1.0685030221939087\n",
      "-- Epoch 950, Train Loss : 0.003968489865656011, Test Loss : 1.2377110719680786\n",
      "-- Epoch 1000, Train Loss : 0.003496004399494268, Test Loss : 1.260468602180481\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Validation Set ----\n",
      "Predictions : torch.Size([1150, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 608\n",
      "False Positive : 114\n",
      "False Negative : 126\n",
      "True Negative : 302\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 84.211 %\n",
      "- Recall : 82.834 %\n",
      "- F1 : 0.83516\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 70.561 %\n",
      "- Recall : 72.596 %\n",
      "- F1 : 0.71564\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 79.13 %\n",
      "- Precision : 77.386 %\n",
      "- Recall : 77.715 %\n",
      "- F1 : 0.7755\n",
      "- Average Confidence : 64.38 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Phemernr1_ResNet10_MLP_DistilBERT_NLI_Mean, 79.13, 77.386, 77.715, 0.7755, 84.211, 82.834, 0.83516, 70.561, 72.596, 0.71564, \n",
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([1154, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 615\n",
      "False Positive : 106\n",
      "False Negative : 158\n",
      "True Negative : 275\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 85.298 %\n",
      "- Recall : 79.56 %\n",
      "- F1 : 0.82329\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 63.51 %\n",
      "- Recall : 72.178 %\n",
      "- F1 : 0.67568\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 77.123 %\n",
      "- Precision : 74.404 %\n",
      "- Recall : 75.869 %\n",
      "- F1 : 0.75129\n",
      "- Average Confidence : 64.05 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Phemernr1_ResNet10_MLP_DistilBERT_NLI_Mean, 77.123, 74.404, 75.869, 0.75129, 85.298, 79.56, 0.82329, 63.51, 72.178, 0.67568, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"Phemernr1_ResNet10_MLP_{unique_name}\"\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(ResNet10(), train_vectors.shape[1], criterion=nn.BCELoss, n_features=16) #, device=\"cpu\")\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=1024)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Validation Set ----\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=val_labels,\n",
    "    predictions=[p[0] for p in preds],\n",
    "    binary=True,\n",
    "    model_name=model_name\n",
    ")\n",
    "conf_mat.evaluate()\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=test_labels,\n",
    "    predictions=[p[0] for p in preds],\n",
    "    binary=True,\n",
    "    model_name=model_name\n",
    ")\n",
    "conf_mat.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "424621e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Phemernr1_ResNet18_MLP_DistilBERT_NLI_Mean\n",
      "Using cuda\n",
      "Saving after new best accuracy : 59.826\n",
      "Saving after new best accuracy : 66.696\n",
      "Saving after new best accuracy : 68.261\n",
      "Saving after new best accuracy : 70.087\n",
      "Saving after new best accuracy : 71.826\n",
      "Saving after new best accuracy : 74.348\n",
      "Saving after new best accuracy : 75.652\n",
      "Saving after new best accuracy : 76.0\n",
      "Saving after new best accuracy : 76.087\n",
      "Saving after new best accuracy : 76.435\n",
      "Saving after new best accuracy : 76.609\n",
      "Saving after new best accuracy : 76.696\n",
      "Saving after new best accuracy : 76.87\n",
      "Saving after new best accuracy : 77.13\n",
      "-- Epoch 50, Train Loss : 0.11866685096174479, Test Loss : 0.589926540851593\n",
      "Saving after new best accuracy : 77.478\n",
      "-- Epoch 100, Train Loss : 0.056492417585104704, Test Loss : 0.6554558873176575\n",
      "Saving after new best accuracy : 77.652\n",
      "Saving after new best accuracy : 78.348\n",
      "Saving after new best accuracy : 78.957\n",
      "-- Epoch 150, Train Loss : 0.05063247587531805, Test Loss : 0.6628289818763733\n",
      "-- Epoch 200, Train Loss : 0.028145801974460483, Test Loss : 0.7459242343902588\n",
      "-- Epoch 250, Train Loss : 0.019981693476438522, Test Loss : 0.8016682863235474\n",
      "-- Epoch 300, Train Loss : 0.015107923187315464, Test Loss : 0.8498267531394958\n",
      "-- Epoch 350, Train Loss : 0.012309934245422482, Test Loss : 0.9587280750274658\n",
      "-- Epoch 400, Train Loss : 0.009501966182142496, Test Loss : 0.9997164011001587\n",
      "-- Epoch 450, Train Loss : 0.007767737319227308, Test Loss : 1.0269827842712402\n",
      "-- Epoch 500, Train Loss : 0.006040574036887847, Test Loss : 1.0624006986618042\n",
      "-- Epoch 550, Train Loss : 0.00505238541518338, Test Loss : 1.0922008752822876\n",
      "-- Epoch 600, Train Loss : 0.00426719436654821, Test Loss : 1.1202675104141235\n",
      "-- Epoch 650, Train Loss : 0.003639569229562767, Test Loss : 1.1468043327331543\n",
      "-- Epoch 700, Train Loss : 0.003127084070001729, Test Loss : 1.1703523397445679\n",
      "-- Epoch 750, Train Loss : 0.002702808393223677, Test Loss : 1.1939584016799927\n",
      "-- Epoch 800, Train Loss : 0.002346305402170401, Test Loss : 1.2169287204742432\n",
      "-- Epoch 850, Train Loss : 0.002045508248556871, Test Loss : 1.2397102117538452\n",
      "-- Epoch 900, Train Loss : 0.0017896902572829276, Test Loss : 1.2613563537597656\n",
      "-- Epoch 950, Train Loss : 0.0015695654728915542, Test Loss : 1.2830488681793213\n",
      "-- Epoch 1000, Train Loss : 0.0013801679961034097, Test Loss : 1.3038309812545776\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAFXCAYAAABTHGLfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjRElEQVR4nO3de3wU9b3/8dfHQAggxwtERJBEWmulFEJJRVAqiq0WtdieWovRYvWUo/YIqNWi9GL9lR7tr97QVsVfEavRWmtRf6L1QkWxKjaxiCB6vAVBuQQqyEXk9jl/zASWmDCbYS/ZzPv5eOyDne/MznxnMux7PzOzs+buiIiI7M5e+e6AiIi0fgoLERGJpLAQEZFICgsREYmksBARkUgKCxERiaSwEInBzIaZ2Rs5XN5/m9mEXC2vieVfaWZ372b8S2b2hVz2SXJLYSEtZmZ1ZnZ8vvuRS2bmZvbZhmF3n+Puh+Vo2aXA94DbcrG8mH4DXJXvTkj2KCxEUphZu3z3oQlnA4+6+8f57shuPAwca2YH5rsjkh0KC8kYM+tgZjeY2Qfh4wYz6xCO62Zmj5jZGjP7l5nNMbO9wnE/NrP3zWydmb1hZiOamf8+ZvYHM6s3s8Vm9hMz2ytc7hoz65cybamZfWxmB4TDJ5vZvHC6582sf8q0dWEf5gMbGgeGmT0bPn3FzNab2elmNtzMljaax6VmNt/MNpjZ782su5k9Fq7XU2a2X8r0R4b9WGNmr5jZ8N1s2q8DzzTqU9T6XG5mr5nZh2Z2h5mVpIz/gZm9Ff4dHjazg1LGfcHMngzHrTCzK1IWWxxu/3VmttDMKhtGuPsmoBY4YTfrIYXM3fXQo0UPoA44von2q4AXgQOAUuB54P+E4/4buBVoHz6GAQYcBiwBDgqnKwc+08xy/wA8BHQJp/sf4Nxw3DRgcsq0PwT+Gj4fCKwEBgNFwJhwHTqkrM884GCgYzPLduCzKcPDgaWNtsmLQHegZ7i8l8NllwB/A34eTtsTWA2MJPjA9tVwuLSZZdcDX04ZTmd9FoTrsz/wd+CX4bjjgFXAl4AOwE3As+G4LsAy4JKwz12AweG4K4FNYZ+Lwr/ni436OQW4Lt/7px7ZeaiykEyqAq5y95XuXg/8AjgrHLcF6AGUufsWD475O7CN4E2rr5m1d/c6d3+78YzNrAj4LnC5u69z9zrg2pT53xOOb3BG2AYwFrjN3ee6+zZ3vxP4BDgyZfop7r7E9+xQz03uvsLd3wfmAHPd/Z8efOqeQfAmD3AmwWGlR919u7s/CdQQvBE3ZV9gXcpwOutzc7g+/wImA6PD9ipgmru/7O6fAJcDQ8ysHDgZWO7u17r7pnA7z02Z53Nhn7cBdwEDGvVzXdhXaYMUFpJJBwGLU4YXh20A/xd4C3jCzN4xs4kA7v4WMIHgk+tKM/tj6mGRFN0IKpLG8+8ZPn8a6GRmg8M3vgqCN2iAMuCS8JDNGjNbQ/CpO3U5S1q6sk1YkfL84yaG907pz2mN+nM0QZg25UOCT/kNWro+qX+HXf5G7r6eoKrpGc7jU0GdYnnK841ASaNDdl2ANbt5vRQwhYVk0gcEb2QNeodthJ9SL3H3PsA3gIsbzk24+z3ufnT4WgeuaWLeqwiqk8bzfz+cxzbgTwSfoEcDj7h7w6fxJQSHqPZNeXRy93tT5pXL2y8vAe5q1J/O7n51M9PPBz7X6PVR63NwyvMdfwca/Y3MrDPQlWA7LgH67MF6HQ68sgevl1ZMYSFxtTezkpRHO+Be4CfhyeVuwM+Au2HHCdnPmpkBawkOP203s8PM7LjwRPgmgk/g2xsvLCUMJptZFzMrAy5umH/oHuB0gkMt96S03w6cF1YdZmadzewkM0v9tB5lBXv2RprqbuAUMzvBzIrC7TfczHo1M/2jwDEpw+mszw/NrJeZ7Q9MAu4L2+8Fvm9mFeE2/xXB4bI64BGgh5lNCC8a6GJmg9NZofAE+iDgyTS3gRQYhYXE9SjBG3vD40rglwTH3ucDrxKc4P1lOP2hwFPAeuAF4Hfu/jTB+YqrCSqH5QQnxy9vZpkXAhuAd4DnCAJhWsPI8Pj6BoJDLY+ltNcAPwBuJjik8xbB5agtcSVwZ3jY5zstfO0u3H0JMAq4guDk9RLgUpr///gHYKSZdQxfn8763AM8QbCt3ib8O7j7U8BPgQcITmZ/hvBcT1iJfRU4heBv8SZwbJqrdQow290/iJxSCpIF5xhFpDUzs18BK939hjSmrQP+IwyGnDCzuQRXpi3I1TIlt1rjF5BEpBF3vyJ6qvxx97QOV0nh0mEoERGJpMNQIiISSZWFiIhEUliIiEikgjjB3a1bNy8vL89fB2prmx83aFDu+iEi0gK1tbWr3L00E/MqiLAoLy+npqYmnx2AxYs/3V5WBvnsl4jIbphZE29c8egwVDomT4ZOnXZt69QpaBcRSQCFRTqqqmDq1J3DZWXBcFVV/vokIpJDCot0pQZDXZ2CQkQSRWEhIiKRFBYiIhJJYSEiIpEUFiIiEklhISIikRQWIiISSWEhIiKRFBYiIhJJYSEiIpEUFiIiEklhISIikRQWIiISSWEhIiKRFBYiIhJJYSEiIpEUFiIiEklhISIikRQWIiISSWEhIiKRFBYiIhJJYSEiIpEUFiIiEklhISIikRQWIiISSWEhIiKRFBYiIhJJYSEiIpEUFiIiEklhISIikRQWIiISSWEhIiKRFBYiIhJJYSEiIpEUFiIiEklhISIikRQWIiISSWEhIiKRFBYiIhIpa2FhZgeb2dNm9pqZLTSz8WH7lWb2vpnNCx8js9WHrHHPdw9ERHKqXRbnvRW4xN1fNrMuQK2ZPRmOu97df5PFZWeXO5jluxciIjmTtbBw92XAsvD5OjNbBPTM1vJERCR7cnLOwszKgYHA3LDpv8xsvplNM7P9mnnNWDOrMbOa+vr6XHQzfToMJSIJk/WwMLO9gQeACe7+EXAL8BmggqDyuLap17n7VHevdPfK0tLSbHezZRQWIpIwWQ0LM2tPEBTV7v4XAHdf4e7b3H07cDtwRDb7kBUKCxFJmGxeDWXA74FF7n5dSnuPlMm+CSzIVh+yRmEhIgmTzauhjgLOAl41s3lh2xXAaDOrAByoA/4zi33IDoWFiCRMNq+Geg5o6vrSR7O1zJxRWIhIwugb3HEoLEQkYRQWIiISSWERhyoLEUkYhUUcCgsRSRiFRRwKCxFJGIVFHAoLEUkYhUUcCgsRSRiFRRwKCxFJGIWFiIhEUljEocpCRBJGYRGHwkJEEkZhEYfCQkQSRmERh8JCRBJGYRGHwkJEEkZhEYfCQkQSRmERh8JCRBJGYSEiIpEUFnGoshCRhFFYxKGwEJGEUVjEobAQkYRRWMShsBCRhFFYxKGwEJGEUVjEobAQkYRRWIiISCSFRRyqLEQkYRQWcSgsRCRhFBZxKCxEJGEUFnEoLEQkYRQWcSgsRCRhFBZxKCxEJGEUFnEoLEQkYRQWIiISSWERhyoLEUkYhUUcCgsRSRiFRRwKCxFJGIVFHAoLEUkYhUUcCgsRSRiFRRwKCxFJmKyFhZkdbGZPm9lrZrbQzMaH7fub2ZNm9mb4737Z6kPWKCxEJGGyWVlsBS5x977AkcAPzawvMBGY5e6HArPCYRERacWyFhbuvszdXw6frwMWAT2BUcCd4WR3Aqdmqw9Zo8pCRBImJ+cszKwcGAjMBbq7+7Jw1HKgezOvGWtmNWZWU19fn4tupk9hISIJk/WwMLO9gQeACe7+Ueo4d3egyXded5/q7pXuXllaWprtbraMwkJEEiarYWFm7QmCotrd/xI2rzCzHuH4HsDKbPYhY6qrdz4/4YRdh0VE2rhsXg1lwO+BRe5+Xcqoh4Ex4fMxwEPZ6kPGVFfD2LE7h5ctC4YVGCKSEOZZOqRiZkcDc4BXge1h8xUE5y3+BPQGFgPfcfd/7W5elZWVXlNTk5V+pqW8HBYv/nR7WRnU1eW6NyIiaTGzWnevzMS82mViJk1x9+cAa2b0iGwtNyvee69l7SIibYy+wZ2O3r1b1i4i0sYoLNIxeTJ06rRrW6dOQbuISAIoLNJRVQVTp+4cPvDAYLiqKn99EhHJIYVFulKDYeZMBYWIJIrCIg59KU9EEkZhISIikRQWcaiyEJGEUViIiEgkhUUcqixEJGEUFiIiEklhEYcqCxFJGIWFiIhEUljEocpCRBJGYSEiIpEUFnGoshCRhFFYiIhIJIVFHKosRCRhFBYiIhJJYRGHKgsRSRiFhYiIRFJYxKHKQkQSRmEhIiKRFBZxqLIQkYRRWIiISCSFRRyqLEQkYRQWIiISSWERhyoLEUkYhYWIiERSWMShykJEEkZhISIikRQWcaiyEJGEUViIiEgkhUUcqixEJGHSCgsz62xme4XPP2dm3zCz9tntmoiItBbpVhbPAiVm1hN4AjgLmJ6tTrV6qixEJGHSDQtz943At4DfuftpwBey1y0REWlN0g4LMxsCVAEzw7ai7HSpAKiyEJGESTcsJgCXAzPcfaGZ9QGezlqvRESkVUkrLNz9GXf/hrtfE57oXuXu43b3GjObZmYrzWxBStuVZva+mc0LHyP3sP/5ocpCRBIm3auh7jGzfzOzzsAC4DUzuzTiZdOBE5tov97dK8LHoy3rroiI5EO6h6H6uvtHwKnAY8AhBFdENcvdnwX+tUe9a61UWYhIwqQbFu3D71WcCjzs7luAuO+Y/2Vm88PDVPs1N5GZjTWzGjOrqa+vj7koERHJhHTD4jagDugMPGtmZcBHMZZ3C/AZoAJYBlzb3ITuPtXdK929srS0NMaiskiVhYgkTLonuKe4e093H+mBxcCxLV2Yu69w923uvh24HTiipfMQEZHcS/cE9z5mdl3DYSEzu5agymgRM+uRMvhNgpPlhUeVhYgkTLs0p5tG8Mb+nXD4LOAOgm90N8nM7gWGA93MbCnwc2C4mVUQnO+oA/4zTqdFRCS30g2Lz7j7v6cM/8LM5u3uBe4+uonm36fbsVZNlYWIJEy6J7g/NrOjGwbM7Cjg4+x0SUREWpt0K4vzgD+Y2T7h8IfAmOx0qQCoshCRhEkrLNz9FWCAmf1bOPyRmU0A5mexbyIi0kq06Jfy3P2j8JvcABdnoT+FQZWFiCTMnvysqmWsFyIi0qrtSVgk9+O1KgsRSZjdnrMws3U0HQoGdMxKj0REpNXZbVi4e5dcdaSgqLIQkYTZk8NQIiKSEAqLOFRZiEjCKCxERCSSwiIOVRYikjAKCxERiaSwiEOVhYgkjMJCREQiKSziUGUhIgmjsBARkUgKizhUWYhIwigsREQkksIiDlUWIpIwCgsREYmksIhDlYWIJIzCQkREIiks4lBlISIJo7AQEZFICos4VFmISMIoLEREJJLCIg5VFiKSMAoLERGJpLCIQ5WFiCSMwkJERCIpLOJQZSEiCaOwEBGRSAqLOFRZiEjCKCxERCSSwiIOVRYikjAKCxERiaSwiEOVhYgkTNbCwsymmdlKM1uQ0ra/mT1pZm+G/+6XreWLiEjmZLOymA6c2KhtIjDL3Q8FZoXDhUeVhYgkTNbCwt2fBf7VqHkUcGf4/E7g1GwtP6sUFiKSMLk+Z9Hd3ZeFz5cD3Zub0MzGmlmNmdXU19fnpnciItKkvJ3gdncHmv2I7u5T3b3S3StLS0tz2LM0qLIQkYTJdVisMLMeAOG/K3O8fBERiSHXYfEwMCZ8PgZ4KMfLzwxVFiKSMNm8dPZe4AXgMDNbambnAlcDXzWzN4Hjw2EREWnl2mVrxu4+uplRI7K1zJxRZSEiCaNvcIuISCSFRRyqLEQkYRQWIiISSWERhyoLEUkYhYWIiERSWMShykJEEkZhISIikRQWcaiyEJGEUViIiEgkhUUcqixEJGEUFiIiEklhEYcqCxFJGIWFiIhEUljEocpCRBJGYSEiIpEUFnGoshCRhFFYiIhIJIVFHKosRCRhFBYiIhJJYRGHKgsRSRiFhYiIRFJYxKHKQkQSRmEhIiKRFBZxqLIQkYRRWLSEWb57ICKSFwqLOFRZiEjCKCxERCSSwiIOVRYikjAKCxERiaSwiEOVhYgkjMKiJXQ1lIgklMIiDlUWIpIwCgsREYmksIhDlYWIJIzCQkREIiks4lBlISIJo7BoCV0NJSIJpbCIQ5WFiCRMu3ws1MzqgHXANmCru1fmox8iIpKevIRF6Fh3X5XH5cenykJEEkaHoVpC5yxEJKHyFRYOPGFmtWY2Nk99iE+VhYgkTL4OQx3t7u+b2QHAk2b2urs/mzpBGCJjAXr37p2PPoqISCgvlYW7vx/+uxKYARzRxDRT3b3S3StLS0tz3cXdU2UhIgmT87Aws85m1qXhOfA1YEGu+yEiIunLx2Go7sAMC04WtwPucfe/5qEf8amyEJGEyXlYuPs7wIBcLzcjdDWUiCSULp2NQ5WFiCSMwkJERCIpLOJQZSEiCaOwEBGRSPm8N1RBqa6G07ZAMfDrXzs9e0NVVb57JVKYtmzZwtKlS9m0aVO+u9ImlJSU0KtXL9q3b5+1ZSgs0lBdDWPHwrcJroZaswZ+Ed6kRIEh0nJLly6lS5culJeXY7rKcI+4O6tXr2bp0qUccsghWVuODkOlYdIk2Lhx57DhbNwYtItIy23atImuXbsqKDLAzOjatWvWqzSFRRree69l7SISTUGRObnYlgqLNDS+j6HhTbaLSGFYvXo1FRUVVFRUcOCBB9KzZ88dw5s3b97ta2tqahg3blyLlldeXs6qVYX58z0NFBZpmDwZiovB2ZnexcVBu4hkX3U1lJfDXnsF/1ZX79n8unbtyrx585g3bx7nnXceF1100Y7h4uJitm7d2uxrKysrmTJlyp51oAAVRFjU1mZmB9kTqV+tMFxftRDJkYYLTBYvDv4fLl4cDGf6/eDss8/mvPPOY/DgwVx22WW89NJLDBkyhIEDBzJ06FDeeOMNAGbPns3JJ58MwJVXXsk555zD8OHD6dOnT4tCpK6ujuOOO47+/fszYsQI3guPa99///3069ePAQMG8JWvfAWAhQsXcsQRR1BRUUH//v158803M7vyaSiYq6EadhDI/RVIkybBli27tm3ZErTraiiRPTNhAsyb1/z4F1+ETz7ZtW3jRjj3XLj99qZfU1EBN9zQ8r4sXbqU559/nqKiIj766CPmzJlDu3bteOqpp7jiiit44IEHPvWa119/naeffpp169Zx2GGHcf7556d1CeuFF17ImDFjGDNmDNOmTWPcuHE8+OCDXHXVVTz++OP07NmTNWvWAHDrrbcyfvx4qqqq2Lx5M9u2bWv5yu2hgqgsGuTrCqTGJ7IbzlnoBLdI9jUOiqj2PXHaaadRVFQEwNq1aznttNPo168fF110EQsXLmzyNSeddBIdOnSgW7duHHDAAaxYsSKtZb3wwgucccYZAJx11lk899xzABx11FGcffbZ3H777TtCYciQIfzqV7/immuuYfHixXTs2HFPV7XFCqayaJCPN+jevYPKpql2EdkzURVAeXnT///KymD27Mz2pXPnzjue//SnP+XYY49lxowZ1NXVMXz48CZf06FDhx3Pi4qKdnu+Ix233norc+fOZebMmQwaNIja2lrOOOMMBg8ezMyZMxk5ciS33XYbxx133B4tp6UKqrKA/LxBT54MnTrtHDacTp10glskFxr//wNy8v9v7dq19OzZE4Dp06dnfP5Dhw7lj3/8IwDV1dUMGzYMgLfffpvBgwdz1VVXUVpaypIlS3jnnXfo06cP48aNY9SoUcyfPz/j/YlSUGGRrzfoqiqYOnXn1VAdS4Jhna8Qyb6G/39lZcFPypSV5eb/32WXXcbll1/OwIED97haAOjfvz+9evWiV69eXHzxxdx0003ccccd9O/fn7vuuosbb7wRgEsvvZQvfvGL9OvXj6FDhzJgwAD+9Kc/0a9fPyoqKliwYAHf+9739rg/LWVeAJf1mFV6WVkNkyfn9w16014dKfFNXMnPmV52Zd77I1KoFi1axOGHH57vbrQpTW1TM6t198pMzL8gzlkUF0NdXX77UF0N30rJ1XxenSUikmsFcRhq+/Z892DXq7AarobS/aFEJCkKIiy2bs3/l/Lee29nSDRuFxFp6woiLCB739pMV+pVWKmhoctnRSQJCiYsIL+HfZq6CkuXz4pIUhRUWED+DvtUVQWX7UFQWeTq8j0RkdagIK6GSrX//vlbthXAZcYiEm316tWMGDECgOXLl1NUVERpaSkAL730EsXFxbt9/ezZsykuLmbo0KGfGjd9+nRqamq4+eabM9/xPCq4ymLduvyct6iuZseZCsPzfg5FJFEyfI/yqFuUR5k9ezbPP//8HvWh0BRcWGzenJ/zFpMmwV4EN/WaxGTepZxRG6t16axItuXoHuW1tbUcc8wxDBo0iBNOOIFly5YBMGXKFPr27Uv//v357ne/S11dHbfeeivXX389FRUVzJkzJ635X3fddfTr149+/fpxQ3hDrA0bNnDSSScxYMAA+vXrx3333QfAxIkTdyzzRz/6UUbXM66COwwF+TlvcdTiatqFYWFAOYu5nbGMXQygExcisbWCe5S7OxdeeCEPPfQQpaWl3HfffUyaNIlp06Zx9dVX8+6779KhQwfWrFnDvvvuy3nnncfee++d9ht5bW0td9xxB3PnzsXdGTx4MMcccwzvvPMOBx10EDNnzgSC+1GtXr2aGTNm8Prrr2NmO25Tnm8FGRb5OG9xTdEkrNEt5DuzkWuKJqGwEMmgTZt2/QGZ3d2jfN26psetWAE1Nekt74MP+KSoiAXz5/PVo44CYNv27fTo1g1qauhfVkbVyJGceswxnDp8eHAZ5AcfQMeOTS/j3Xdh5cpdxj137718c/BgOi9aBMC3jjySOdXVnDhkCJfMnMmPx4zh5KOPZlh4H6oSd84dNYqTjz6ak4cNgzR+H4NVq6Bv312aBsGg9DZCtIIMi3zoua3pcqa5dpFIxx8Ps2bluxf58dhjsGFD8PzMM4NHc045BZYv/3T7gQfCbbdlpDvuzhf69OGFadM+NW7mDTfw7D//yf+fM4fJd9zBq/fem5FlAnyurIyX77qLR//+d35yyy2M+PKX+dkPfsBL06cz6x//4M+zZnHz/ffzt1tuydgy4yq4cxYAq1fnfpnvFzX97bvm2iUDLrgguF65rT6SGhQtdcEFUFKya1tJSdCeIR2Ki6n/8ENeCG/9vWXrVha+/Tbbt29nyYoVHFtZyTUXXsja9etZ//HHdOnUiXUbN6Y9/2EDB/LgM8+wcdMmNnz8MTNmz2bYwIF8UF9Pp5ISzhw5kkvPOouX33iD9Rs3snb9ekYedRTXX3wxr+ThJ1SbUrCVRbducOONufuew0PbRnIBt4Q3KQ9soBOXbZvM8+XoDrQNqqvhnHOCKxFEMuHrXw/+/d3vgsNL3bsHQdHQngF7mfHnq69m3LXXsnb9erZu3cqE0aP5XFkZZ/7sZ6xdvx53Z9zpp7Nvly6cMmwY3544kYeeeYabLr2UYQMH7jK/6Y88woPPPLNj+MVp0zj75JM5YswYAP5j1CgGHnYYj7/wApdOmcJeZrRv145bJk5k3caNjLrkEjZt3oy7c92ECRlbzz1RMLcoh08fGywuhmnTcvAmXV3NxrPG0sl3fpJo2GrbKOJWxvLjTr/L/5f0knxYQwrKosce4/Bu3fLdjTZl0apVHN4oQCuBGndr+hUtUxCHoQZRy3Zsx+NdyhlNNZs3w/jxOejA+PG7BAUEV0QZ0I5t/JBb+MvG43d/Ge3xx+uwhogUrII5DJUajeUsppozqeZMWN1oZB4Y8DVm8e5iy3tfRESyoWDCorHW9p7c2voj0iaYBd/Y7to13z1p/RYtCr60mKLWrDZTsy/YsBBpU0aMgKeeyncvcmfRIvzzn8dMH7MyIRfnngvinIUIJSVw993BJ6e2+EhSUAAlJSWsXr06J29ybZ27s3r1akoaX16cYaosJPvKynRtseyiV69eLF26lPr6+nx3pU0oKSmhV69eWV2GwiIP4n6WalHBnrTDGlJQ2rdvzyGHHJLvbkgLtImwyGUhG/WGnU5fnmAEJ5LlN/JZ6Ky7SOINyti9oQrjnMWgQXD33WwtKsZhl0c9XanibvbCs/6o4m4+ovOn+tDw2A78lvMj55P1oBARybCC+AZ3ZWWl14R3cLzgAmgF99QSESkAlbjXZOQYQ0GEhZmtA97Y2dJtf+hdvvNXsUVE5NPqcF+VkffJQjln8Ya7V+a7E62BmdVoWwS0LXbStthJ22InM0vzRz2iFcY5CxERySuFhYiIRCqUsJia7w60ItoWO2lb7KRtsZO2xU4Z2xYFcYJbRETyq1AqCxERyaNWHRZmdqKZvWFmb5nZxHz3J9vM7GAze9rMXjOzhWY2Pmzf38yeNLM3w3/3C9vNzKaE22e+mX0pv2uQeWZWZGb/NLNHwuFDzGxuuM73mVlx2N4hHH4rHF+e145nmJnta2Z/NrPXzWyRmQ1J6n5hZheF/z8WmNm9ZlaSlP3CzKaZ2UozW5DS1uL9wMzGhNO/aWZj0ll2qw0LMysCfgt8HegLjDazvvntVdZtBS5x977AkcAPw3WeCMxy90MJbuTREJxfBw4NH2OBtvh1xfHAopTha4Dr3f2zwIfAuWH7ucCHYfv14XRtyY3AX93988AAgm2SuP3CzHoC44BKd+8HFAHfJTn7xXTgxEZtLdoPzGx/4OfAYOAI4OcNAbNb7t4qH8AQ4PGU4cuBy/Pdrxxvg4eArxJ8IbFH2NaD4HsnALcBo1Om3zFdW3gAvcKd/zjgEYK7Xa0C2jXeR4DHgSHh83bhdJbvdcjQdtgHeLfx+iRxvwB6AkuA/cO/8yPACUnaL4ByYEHc/QAYDdyW0r7LdM09Wm1lwc6dosHSsC0RwnJ5IDAX6O7uy8JRy4Hu4fO2vo1uAC4juO0WQFdgjbtvDYdT13fHtgjHrw2nbwsOAeqBO8JDcv/PzDqTwP3C3d8HfgO8Bywj+DvXksz9okFL94NY+0drDovEMrO9gQeACe7+Ueo4Dz4KtPlL2MzsZGClu2fsZyELWDvgS8At7j4Q2MDOQw1AovaL/YBRBAF6ENCZTx+WSaxs7getOSzeBw5OGe4VtrVpZtaeICiq3f0vYfMKM+sRju8BrAzb2/I2Ogr4hpnVAX8kOBR1I7CvmTXcpiZ1fXdsi3D8PsDqXHY4i5YCS919bjj8Z4LwSOJ+cTzwrrvXu/sW4C8E+0oS94sGLd0PYu0frTks/gEcGl7lUExwEuvhPPcpqyz4QeLfA4vc/bqUUQ8DDVcsjCE4l9HQ/r3wqocjgbUp5WhBc/fL3b2Xu5cT/O3/5u5VwNPAt8PJGm+Lhm307XD6NvFJ292XA0vM7LCwaQTwGgncLwgOPx1pZp3C/y8N2yJx+0WKlu4HjwNfM7P9wkrta2Hb7uX7ZE3EiZyRwP8AbwOT8t2fHKzv0QQl5HxgXvgYSXCMdRbwJvAUsH84vRFcMfY28CrBFSJ5X48sbJfhwCPh8z7AS8BbwP1Ah7C9JBx+KxzfJ9/9zvA2qABqwn3jQWC/pO4XwC+A14EFwF1Ah6TsF8C9BOdqthBUnOfG2Q+Ac8Jt8hbw/XSWrW9wi4hIpNZ8GEpERFoJhYWIiERSWIiISCSFhYiIRFJYiIhIJIWFCGBm28xsXsojY3c5NrPy1LuEihSidtGTiCTCx+5eke9OiLRWqixEdsPM6szs12b2qpm9ZGafDdvLzexv4e8EzDKz3mF7dzObYWavhI+h4ayKzOz28HcYnjCzjnlbKZEYFBYigY6NDkOdnjJurbt/EbiZ4E64ADcBd7p7f6AamBK2TwGecfcBBPdvWhi2Hwr81t2/AKwB/j2rayOSYfoGtwhgZuvdfe8m2uuA49z9nfAmj8vdvauZrSL4DYEtYfsyd+9mZvVAL3f/JGUe5cCTHvw4DWb2Y6C9u/8yB6smkhGqLESieTPPW+KTlOfb0PlCKTAKC5Fop6f8+0L4/HmCu+ECVAFzwuezgPNhx++H75OrTopkkz7diAQ6mtm8lOG/unvD5bP7mdl8gupgdNh2IcEv111K8Ct23w/bxwNTzexcggrifIK7hIoUNJ2zENmN8JxFpbuvyndfRPJJh6FERCSSKgsREYmkykJERCIpLEREJJLCQkREIiksREQkksJCREQiKSxERCTS/wLmNqcRyCwQjgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Validation Set ----\n",
      "Predictions : torch.Size([1150, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 637\n",
      "False Positive : 145\n",
      "False Negative : 97\n",
      "True Negative : 271\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 81.458 %\n",
      "- Recall : 86.785 %\n",
      "- F1 : 0.84037\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 73.641 %\n",
      "- Recall : 65.144 %\n",
      "- F1 : 0.69133\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 78.957 %\n",
      "- Precision : 77.55 %\n",
      "- Recall : 75.964 %\n",
      "- F1 : 0.76749\n",
      "- Average Confidence : 72.65 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Phemernr1_ResNet18_MLP_DistilBERT_NLI_Mean, 78.957, 77.55, 75.964, 0.76749, 81.458, 86.785, 0.84037, 73.641, 65.144, 0.69133, \n",
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([1154, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 673\n",
      "False Positive : 152\n",
      "False Negative : 100\n",
      "True Negative : 229\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 81.576 %\n",
      "- Recall : 87.063 %\n",
      "- F1 : 0.8423\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 69.605 %\n",
      "- Recall : 60.105 %\n",
      "- F1 : 0.64507\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 78.163 %\n",
      "- Precision : 75.59 %\n",
      "- Recall : 73.584 %\n",
      "- F1 : 0.74574\n",
      "- Average Confidence : 73.2 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Phemernr1_ResNet18_MLP_DistilBERT_NLI_Mean, 78.163, 75.59, 73.584, 0.74574, 81.576, 87.063, 0.8423, 69.605, 60.105, 0.64507, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"Phemernr1_ResNet18_MLP_{unique_name}\"\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(ResNet18(), train_vectors.shape[1], criterion=nn.BCELoss, n_features=16) #, device=\"cpu\")\n",
    "model.train_eval(torch.Tensor(train_vectors),\n",
    "                torch.Tensor(train_labels),\n",
    "                torch.Tensor(val_vectors),\n",
    "                torch.Tensor(val_labels),\n",
    "                saves=model_name,\n",
    "                n_iter=1000,\n",
    "                batch_size=1024)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Validation Set ----\")\n",
    "preds = model.predict(val_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=val_labels,\n",
    "    predictions=[p[0] for p in preds],\n",
    "    binary=True,\n",
    "    model_name=model_name\n",
    ")\n",
    "conf_mat.evaluate()\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors)\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=test_labels,\n",
    "    predictions=[p[0] for p in preds],\n",
    "    binary=True,\n",
    "    model_name=model_name\n",
    ")\n",
    "conf_mat.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61ccef0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Phemernr1_ResNet10_CNN_DistilBERT_NLI_Mean\n",
      "\n",
      "---- Validation Set ----\n",
      "Predictions : torch.Size([1150, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 657\n",
      "False Positive : 93\n",
      "False Negative : 77\n",
      "True Negative : 323\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 87.6 %\n",
      "- Recall : 89.51 %\n",
      "- F1 : 0.88544\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 80.75 %\n",
      "- Recall : 77.644 %\n",
      "- F1 : 0.79167\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 85.217 %\n",
      "- Precision : 84.175 %\n",
      "- Recall : 83.577 %\n",
      "- F1 : 0.83875\n",
      "- Average Confidence : 73.29 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Phemernr1_ResNet10_CNN_DistilBERT_NLI_Mean, 85.217, 84.175, 83.577, 0.83875, 87.6, 89.51, 0.88544, 80.75, 77.644, 0.79167, \n",
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([1154, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 698\n",
      "False Positive : 94\n",
      "False Negative : 75\n",
      "True Negative : 287\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 88.131 %\n",
      "- Recall : 90.298 %\n",
      "- F1 : 0.89201\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 79.282 %\n",
      "- Recall : 75.328 %\n",
      "- F1 : 0.77254\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 85.355 %\n",
      "- Precision : 83.707 %\n",
      "- Recall : 82.813 %\n",
      "- F1 : 0.83258\n",
      "- Average Confidence : 74.21 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Phemernr1_ResNet10_CNN_DistilBERT_NLI_Mean, 85.355, 83.707, 82.813, 0.83258, 88.131, 90.298, 0.89201, 79.282, 75.328, 0.77254, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"Phemernr1_ResNet10_CNN_{unique_name}\"\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(CNNResNet10(), train_vectors.shape[1], criterion=nn.BCELoss, n_features=16, model_type=\"cnn\") #, device=\"cpu\")\n",
    "# model.train_eval(torch.Tensor(train_vectors.reshape(train_vectors.shape[0], 24, 32)),\n",
    "#                 torch.Tensor(train_labels),\n",
    "#                 torch.Tensor(val_vectors.reshape(val_vectors.shape[0], 24, 32)),\n",
    "#                 torch.Tensor(val_labels),\n",
    "#                 saves=model_name,\n",
    "#                 n_iter=1000,\n",
    "#                 batch_size=1024)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Validation Set ----\")\n",
    "preds = model.predict(val_vectors.reshape(val_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=val_labels,\n",
    "    predictions=[p[0] for p in preds],\n",
    "    binary=True,\n",
    "    model_name=model_name\n",
    ")\n",
    "conf_mat.evaluate()\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors.reshape(test_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=test_labels,\n",
    "    predictions=[p[0] for p in preds],\n",
    "    binary=True,\n",
    "    model_name=model_name\n",
    ")\n",
    "conf_mat.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c746093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Classification Phemernr1_ResNet18_CNN_DistilBERT_NLI_Mean\n",
      "\n",
      "---- Validation Set ----\n",
      "Predictions : torch.Size([1150, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 673\n",
      "False Positive : 127\n",
      "False Negative : 61\n",
      "True Negative : 289\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 84.125 %\n",
      "- Recall : 91.689 %\n",
      "- F1 : 0.87744\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 82.571 %\n",
      "- Recall : 69.471 %\n",
      "- F1 : 0.75457\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 83.652 %\n",
      "- Precision : 83.348 %\n",
      "- Recall : 80.58 %\n",
      "- F1 : 0.81941\n",
      "- Average Confidence : 88.57 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Phemernr1_ResNet18_CNN_DistilBERT_NLI_Mean, 83.652, 83.348, 80.58, 0.81941, 84.125, 91.689, 0.87744, 82.571, 69.471, 0.75457, \n",
      "\n",
      "---- Test Set ----\n",
      "Predictions : torch.Size([1154, 1])\n",
      "Binary Class Evaluation\n",
      "\n",
      "True Positive : 711\n",
      "False Positive : 106\n",
      "False Negative : 62\n",
      "True Negative : 275\n",
      "\n",
      "Class positive Evaluation\n",
      "- Precision : 87.026 %\n",
      "- Recall : 91.979 %\n",
      "- F1 : 0.89434\n",
      "\n",
      "Class negative Evaluation\n",
      "- Precision : 81.602 %\n",
      "- Recall : 72.178 %\n",
      "- F1 : 0.76602\n",
      "\n",
      "Combined Evaluation\n",
      "- Accuracy : 85.442 %\n",
      "- Precision : 84.314 %\n",
      "- Recall : 82.079 %\n",
      "- F1 : 0.83181\n",
      "- Average Confidence : 89.94 %\n",
      "Model, Combined,,,,positive,,,negative,,,\n",
      "Phemernr1_ResNet18_CNN_DistilBERT_NLI_Mean, 85.442, 84.314, 82.079, 0.83181, 87.026, 91.979, 0.89434, 81.602, 72.178, 0.76602, \n"
     ]
    }
   ],
   "source": [
    "model_name = f\"Phemernr1_ResNet18_CNN_{unique_name}\"\n",
    "print(f\"Multiclass Classification {model_name}\")\n",
    "model = ResNetClassifier(CNNResNet18(), train_vectors.shape[1], criterion=nn.BCELoss, n_features=16, model_type=\"cnn\") #, device=\"cpu\")\n",
    "# model.train_eval(torch.Tensor(train_vectors.reshape(train_vectors.shape[0], 24, 32)),\n",
    "#                 torch.Tensor(train_labels),\n",
    "#                 torch.Tensor(val_vectors.reshape(val_vectors.shape[0], 24, 32)),\n",
    "#                 torch.Tensor(val_labels),\n",
    "#                 saves=model_name,\n",
    "#                 n_iter=1000,\n",
    "#                 batch_size=1024)\n",
    "\n",
    "model.load_pretrained(f\"../../data/models/{model_name}.pth\")\n",
    "\n",
    "print(\"\\n---- Validation Set ----\")\n",
    "preds = model.predict(val_vectors.reshape(val_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=val_labels,\n",
    "    predictions=[p[0] for p in preds],\n",
    "    binary=True,\n",
    "    model_name=model_name\n",
    ")\n",
    "conf_mat.evaluate()\n",
    "\n",
    "print(\"\\n---- Test Set ----\")\n",
    "preds = model.predict(test_vectors.reshape(test_vectors.shape[0], 1, 24, 32))\n",
    "print(f\"Predictions : {preds.shape}\")\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "\n",
    "conf_mat = ConfusionMatrix(\n",
    "    labels=test_labels,\n",
    "    predictions=[p[0] for p in preds],\n",
    "    binary=True,\n",
    "    model_name=model_name\n",
    ")\n",
    "conf_mat.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d251e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
